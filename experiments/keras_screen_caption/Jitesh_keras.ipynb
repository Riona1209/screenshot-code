{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Embedding,GRU,TimeDistributedDense,RepeatVector,Merge\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing import sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "max_caption_len = 21\n",
    "vocab_size = 43\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    #Remove the last two layers to get the 4096D activations\n",
    "    model.layers.pop()\n",
    "    model.layers.pop()\n",
    "\n",
    "    return model\n",
    "print \"VGG loading\"\n",
    "image_model = VGG_16('vgg16_weights.h5')\n",
    "image_model.trainable = False\n",
    "print \"VGG loaded\"\n",
    "# let's load the weights from a save file.\n",
    "# image_model.load_weights('weight_file.h5')\n",
    "\n",
    "# next, let's define a RNN model that encodes sequences of words\n",
    "# into sequences of 128-dimensional word vectors.\n",
    "print \"Text model loading\"\n",
    "language_model = Sequential()\n",
    "language_model.add(Embedding(vocab_size, 256, input_length=max_caption_len))\n",
    "language_model.add(GRU(output_dim=128, return_sequences=True))\n",
    "language_model.add(TimeDistributedDense(128))\n",
    "print \"Text model loaded\"\n",
    "# let's repeat the image vector to turn it into a sequence.\n",
    "print \"Repeat model loading\"\n",
    "image_model.add(RepeatVector(max_caption_len))\n",
    "print \"Repeat model loaded\"\n",
    "# the output of both models will be tensors of shape (samples, max_caption_len, 128).\n",
    "# let's concatenate these 2 vector sequences.\n",
    "print \"Merging\"\n",
    "model = Sequential()\n",
    "model.add(Merge([image_model, language_model], mode='concat', concat_axis=-1))\n",
    "# let's encode this vector sequence into a single vector\n",
    "model.add(GRU(256, return_sequences=False))\n",
    "# which will be used to compute a probability\n",
    "# distribution over what the next word in the caption should be!\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "print \"Merged\"\n",
    "# \"images\" is a numpy float array of shape (nb_samples, nb_channels=3, width, height).\n",
    "# \"captions\" is a numpy integer array of shape (nb_samples, max_caption_len)\n",
    "# containing word index sequences representing partial captions.\n",
    "# \"next_words\" is a numpy float array of shape (nb_samples, vocab_size)\n",
    "# containing a categorical encoding (0s and 1s) of the next word in the corresponding\n",
    "# partial caption.\n",
    "print \"Data preprocessig\"\n",
    "Texts = [\"START A girl is stretched out in shallow water END\",\n",
    "        \"START The two people stand by a body of water and in front of bushes in fall END\",\n",
    "        \"START A blonde horse and a blonde girl in a black sweatshirt are staring at a fire in a barrel END\",\n",
    "        \"START Children sit and watch the fish moving in the pond END\",\n",
    "        \"START A fisherman fishes at the bank of a foggy river END\"]\n",
    "\n",
    "Images = [\"667626_18933d713e.jpg\",\n",
    "         \"3637013_c675de7705.jpg\",\n",
    "         \"10815824_2997e03d76.jpg\",\n",
    "         \"12830823_87d2654e31.jpg\",\n",
    "         \"17273391_55cfc7d3d4.jpg\"]\n",
    "images = []\n",
    "for image in Images:\n",
    "    img = cv2.imread(image)\n",
    "    img.resize((3,224,224))\n",
    "    images.append(img)\n",
    "images = np.asarray(images)\n",
    "\n",
    "words = [txt.split() for txt in Texts]\n",
    "unique = []\n",
    "for word in words:\n",
    "    unique.extend(word)\n",
    "unique = list(set(unique))\n",
    "word_index = {}\n",
    "index_word = {}\n",
    "for i,word in enumerate(unique):\n",
    "    word_index[word] = i\n",
    "    index_word[i] = word\n",
    "\n",
    "partial_captions = []\n",
    "for text in Texts:\n",
    "    one = [word_index[txt] for txt in text.split()]\n",
    "    partial_captions.append(one)\n",
    "\n",
    "partial_captions = sequence.pad_sequences(partial_captions, maxlen=max_caption_len,padding='post')\n",
    "next_words = np.zeros((5,vocab_size))\n",
    "for i,text in enumerate(Texts):\n",
    "    text = text.split()\n",
    "    x = [word_index[txt] for txt in text]\n",
    "    x = np.asarray(x)\n",
    "    next_words[i,x] = 1\n",
    "\n",
    "print \"Data preprocessing done\"\n",
    "model.fit([images, partial_captions], next_words, batch_size=1, nb_epoch=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
